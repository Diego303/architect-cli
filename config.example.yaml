# ==============================================================================
# architect - Archivo de configuración de ejemplo
# Versión: 0.15.0
#
# Copia este archivo a config.yaml y ajusta según tus necesidades.
#
# Precedencia de configuración (de menor a mayor prioridad):
#   1. Defaults del código
#   2. Este archivo YAML
#   3. Variables de entorno (ARCHITECT_*)
#   4. Flags de línea de comandos (--model, --workspace, etc.)
# ==============================================================================


# ==============================================================================
# LLM - Configuración del modelo de lenguaje
# ==============================================================================
llm:
  # Proveedor: "litellm" (único soportado — abstrae 100+ proveedores)
  provider: litellm

  # Modo de conexión:
  #   direct → llamadas directas al proveedor (OpenAI, Anthropic, etc.)
  #   proxy  → a través de LiteLLM Proxy Server (para equipos o caching)
  mode: direct

  # Modelo a utilizar. Ejemplos:
  #   OpenAI:    gpt-4o, gpt-4o-mini, gpt-4-turbo, o1-mini
  #   Anthropic: claude-sonnet-4-6, claude-opus-4-6, claude-haiku-4-5-20251001
  #   Gemini:    gemini/gemini-2.0-flash, gemini/gemini-1.5-pro
  #   Ollama:    ollama/llama3, ollama/mistral (local, sin API key)
  #   Together:  together_ai/meta-llama/Llama-3-70b-chat-hf
  model: gpt-4o-mini

  # URL base de la API (opcional).
  # Útil para LiteLLM Proxy, endpoints custom o modelos locales.
  # api_base: http://localhost:8000

  # Variable de entorno que contiene la API key.
  # El sistema la leerá de esta variable al inicio.
  # Override con: architect run "..." --api-key sk-...
  api_key_env: LITELLM_API_KEY

  # Timeout en segundos para cada llamada al LLM.
  # Con --timeout N desde CLI este valor se usa también como step_timeout.
  timeout: 60

  # Número de reintentos automáticos ante errores transitorios.
  # Solo se reintenta en: RateLimitError, ServiceUnavailableError,
  # APIConnectionError, Timeout. Los errores de auth no se reintentan.
  # Espera exponencial entre intentos: 2s → 4s → 8s → ... → 60s máx.
  retries: 2

  # Habilitar streaming de respuestas del LLM.
  # Cuando está activo, el texto aparece en tiempo real en el terminal (stderr).
  # Se desactiva automáticamente con --json y --quiet.
  # Desactivar con: architect run "..." --no-stream
  stream: true

  # Marcar el system prompt con cache_control para que el proveedor lo cachee.
  # Reduce el coste 50-90% en llamadas repetidas (Anthropic, OpenAI compatible).
  # En proveedores que no soportan caching, el campo se ignora sin error.
  prompt_caching: false


# ==============================================================================
# Agentes - Configuración de agentes (por defecto y custom)
# ==============================================================================
# Los agentes por defecto (plan, build, resume, review) están siempre disponibles.
# Aquí puedes:
#   1. Sobrescribir su configuración (solo los campos que quieras cambiar)
#   2. Definir agentes completamente nuevos
#
# Lista todos los agentes disponibles con: architect agents -c config.yaml
agents: {}
  # Descomenta los bloques de abajo para personalizar o crear agentes:

  # ── Ejemplo: sobrescribir el agente "build" para ser más estricto ──────────
  # build:
  #   confirm_mode: confirm-all   # Confirmar absolutamente todo
  #   max_steps: 10               # Reducir pasos máximos

  # ── Agente custom: deployment ───────────────────────────────────────────────
  # deploy:
  #   system_prompt: |
  #     Eres un agente de deployment especializado.
  #     Tu trabajo es preparar y validar el código para producción.
  #
  #     Reglas:
  #     - Verifica que existan tests antes de proceder
  #     - Valida configuraciones de producción
  #     - Lee los archivos de CI/CD para entender el contexto
  #     - Genera un reporte de lo que harías antes de actuar
  #
  #   allowed_tools:
  #     - read_file
  #     - list_files
  #     - write_file
  #
  #   confirm_mode: confirm-all   # Deployment siempre con confirmación
  #   max_steps: 10

  # ── Agente custom: documentación ────────────────────────────────────────────
  # documenter:
  #   system_prompt: |
  #     Eres un agente de documentación técnica.
  #     Lee código y genera documentación clara y bien estructurada.
  #
  #     Reglas:
  #     - Documenta funciones, clases y módulos con docstrings
  #     - Usa formato Markdown para archivos .md
  #     - Incluye ejemplos cuando sea útil
  #     - No modifiques lógica del código, solo añade documentación
  #
  #   allowed_tools:
  #     - read_file
  #     - write_file
  #     - list_files
  #
  #   confirm_mode: confirm-sensitive
  #   max_steps: 20

  # ── Agente custom: análisis de seguridad ─────────────────────────────────────
  # security:
  #   system_prompt: |
  #     Eres un experto en seguridad de software.
  #     Analiza el código en busca de vulnerabilidades y problemas de seguridad.
  #
  #     Aspectos a revisar:
  #     - Inyección SQL, XSS, CSRF
  #     - Gestión de secretos y API keys en código
  #     - Validación de entrada de usuario
  #     - Dependencias con CVEs conocidos
  #     - Principio de mínimo privilegio
  #
  #   allowed_tools:
  #     - read_file
  #     - list_files
  #
  #   confirm_mode: yolo    # Solo lectura, sin riesgo
  #   max_steps: 20


# ==============================================================================
# Logging - Configuración del sistema de logs
# ==============================================================================
logging:
  # Nivel base de logging: human | debug | info | warn | error
  # human (default) → Solo trazabilidad del agente (pasos, tools, resultado).
  #   El usuario ve qué hace el agente sin ruido técnico de INFO/DEBUG.
  # info → Operaciones del sistema, config, registros de tools.
  # debug → Args completos, respuestas LLM, timing interno.
  level: human

  # Nivel de verbose para el console handler técnico (stderr).
  # Solo tiene efecto para logs técnicos (INFO/DEBUG), no para logs HUMAN.
  # 0 → Solo warnings y errores técnicos (default — el usuario ve logs HUMAN)
  # 1 → Operaciones del sistema (INFO)
  # 2 → Args completos y respuestas LLM (DEBUG)
  # 3 → Todo: HTTP, payloads completos, timing interno
  #
  # Override con: architect run "..." -v/-vv/-vvv
  verbose: 0

  # Archivo donde guardar logs estructurados en formato JSON Lines.
  # Cada línea es un JSON completo (fácil de parsear con jq).
  # El archivo captura DEBUG completo independientemente del verbose.
  # Ejemplo: logs/session.jsonl
  #
  # file: logs/architect.jsonl


# ==============================================================================
# Workspace - Directorio de trabajo
# ==============================================================================
workspace:
  # Directorio raíz donde el agente puede operar.
  # TODAS las operaciones de archivos quedan confinadas aquí.
  # El sistema previene path traversal (../../etc/passwd).
  # Override con: architect run "..." -w /ruta/al/proyecto
  root: .

  # Permitir la tool delete_file.
  # Por seguridad, está deshabilitado por defecto.
  # Actívalo solo si necesitas que el agente pueda borrar archivos.
  allow_delete: false


# ==============================================================================
# MCP - Model Context Protocol (herramientas remotas)
# ==============================================================================
# Conecta architect a servidores MCP para usar herramientas remotas.
# Las tools MCP son indistinguibles de las locales para el agente.
# Si un servidor no está disponible, el agente funciona sin esas tools.
#
# Deshabilitar MCP completamente con: architect run "..." --disable-mcp
mcp:
  servers: []

  # ── Ejemplo: servidor MCP para operaciones Git ────────────────────────────
  # servers:
  #   - name: git
  #     url: http://localhost:3000
  #     token_env: MCP_GIT_TOKEN   # Variable de entorno con el token Bearer

  # ── Ejemplo: servidor MCP para base de datos ──────────────────────────────
  #   - name: database
  #     url: https://mcp.example.com/db
  #     token_env: MCP_DB_TOKEN

  # ── Ejemplo: múltiples servidores ─────────────────────────────────────────
  #   - name: github
  #     url: http://localhost:3001
  #     token_env: GITHUB_TOKEN
  #
  #   - name: jira
  #     url: http://localhost:3002
  #     token_env: JIRA_TOKEN
  #
  #   - name: internal-tools
  #     url: http://internal.mcp:8080
  #     token: "token-directo"   # No recomendado en producción — usar token_env


# ==============================================================================
# Indexer - Indexación del repositorio (F10)
# ==============================================================================
# El indexador construye un árbol ligero del workspace al iniciar.
# Este árbol se inyecta en el system prompt del agente para que conozca
# la estructura del proyecto sin necesidad de explorar a ciegas.
#
# También habilita las tools: search_code, grep, find_files
indexer:
  # Habilitar el indexador. Con false, el agente no recibe el árbol del proyecto
  # y las tools search_code/grep/find_files siguen disponibles pero sin contexto previo.
  enabled: true

  # Tamaño máximo de archivo a indexar (bytes). Archivos más grandes se omiten.
  # Default: 1MB. Ajustar en repos con archivos de datos grandes.
  max_file_size: 1000000

  # Directorios adicionales a excluir (además de los defaults):
  # .git, node_modules, __pycache__, .venv, venv, dist, build, etc.
  exclude_dirs: []
  # exclude_dirs:
  #   - vendor
  #   - .terraform
  #   - coverage

  # Patrones de archivos adicionales a excluir (además de los defaults):
  # *.pyc, *.min.js, *.map, *.lock, etc.
  exclude_patterns: []
  # exclude_patterns:
  #   - "*.generated.py"
  #   - "*.pb.go"

  # Cache en disco del índice (~5 minutos de TTL).
  # Evita reconstruir el índice en ejecuciones consecutivas.
  use_cache: true


# ==============================================================================
# Context - Gestión del context window (F11)
# ==============================================================================
# El ContextManager evita que el contexto del LLM se llene en tareas largas.
# Actúa en tres niveles progresivos:
#
#   Nivel 1: Truncado de tool results muy largos (siempre activo si max_tool_result_tokens > 0)
#   Nivel 2: Resumen de pasos antiguos con el propio LLM (según summarize_after_steps)
#   Nivel 3: Ventana deslizante con hard limit total de tokens (según max_context_tokens)
context:
  # Tokens máximos por tool result antes de truncar (~4 chars/token).
  # Un read_file de un archivo grande devolverá las primeras 40 y últimas 20 líneas.
  # 0 = sin truncado (no recomendado para repos grandes).
  max_tool_result_tokens: 2000

  # Pasos con tool calls antes de intentar comprimir mensajes antiguos.
  # Cuando el agente supera este número de pasos con tool calls, los pasos
  # más antiguos se resumen en un párrafo usando el propio LLM.
  # 0 = desactivar resumen (los mensajes siguen creciendo sin límite).
  summarize_after_steps: 8

  # Pasos recientes completos a conservar durante la compresión.
  # Ejemplo: si summarize_after_steps=8 y keep_recent_steps=4,
  # cuando hay 9+ pasos se resumen los 5 más antiguos y se conservan los 4 recientes.
  keep_recent_steps: 4

  # Límite hard del context window total estimado en tokens (~4 chars/token).
  # Si la suma de todos los mensajes supera este límite, se eliminan los más
  # antiguos hasta que quepa. Ajustar según el modelo usado.
  #   gpt-4o:              128k tokens
  #   claude-sonnet-4-6:   200k tokens
  #   gpt-4o-mini:          128k tokens
  # 0 = sin límite hard (peligroso para tareas muy largas).
  max_context_tokens: 80000

  # Ejecutar tool calls independientes en paralelo (ThreadPoolExecutor, 4 workers máx).
  # Speedup especialmente notable en tool calls MCP remotas o múltiples búsquedas.
  # Solo aplica cuando hay >1 tool call y ninguna requiere confirmación interactiva.
  parallel_tools: true


# ==============================================================================
# Evaluation - Auto-evaluación del resultado del agente (F12)
# ==============================================================================
# El SelfEvaluator usa el LLM para verificar si la tarea se completó
# correctamente y, en modo "full", reintenta con un prompt de corrección.
#
# Modos disponibles:
#   off   → Sin evaluación (default). No consume tokens extra.
#   basic → Una llamada extra (~500 tokens). Si falla, marca estado como "partial".
#   full  → Hasta max_retries ciclos de evaluación + corrección. Más costoso,
#           pero consigue resultados de mayor calidad en tareas complejas.
#
# Override desde CLI: architect run "..." --self-eval basic|full
evaluation:
  # Modo de evaluación: "off" | basic | full
  mode: "off"

  # Número máximo de reintentos en modo "full" (rango: 1-5).
  # Cada reintento lanza una nueva ejecución completa del agente.
  max_retries: 2

  # Umbral mínimo de confianza para considerar la tarea completada (0.0-1.0).
  # Si el LLM evalúa confianza < threshold, se reintenta (solo en modo "full").
  # 0.8 = requiere 80% de confianza para aceptar el resultado.
  confidence_threshold: 0.8


# ==============================================================================
# Commands - Ejecución de comandos del sistema (F13)
# ==============================================================================
# Habilita la tool run_command para que el agente pueda ejecutar comandos:
# tests (pytest, npm test), linters (ruff, eslint), compiladores (make, tsc),
# scripts, y comandos de consulta (git status, ls, etc.).
#
# Cuatro capas de seguridad integradas:
#   1. Blocklist: rm -rf /, sudo, curl|bash, etc. — bloqueados siempre
#   2. Clasificación: safe/dev/dangerous → política de confirmación dinámica
#   3. Timeouts + output limit: sin procesos colgados ni contextos saturados
#   4. Directory sandboxing: cwd siempre dentro del workspace
#
# Habilitación desde CLI:
#   --allow-commands   → Habilitar (override de enabled)
#   --no-commands      → Deshabilitar (override de enabled)
commands:
  # Si false, run_command no se registra y el agente no puede ejecutar comandos.
  # Habilitar con: architect run "..." --allow-commands
  enabled: true

  # Timeout por defecto en segundos (usado si el agente no especifica uno).
  # Rango: 1-600 segundos.
  default_timeout: 30

  # Número máximo de líneas de stdout/stderr antes de truncar.
  # Evita que outputs de comandos verbosos saturen el context window del LLM.
  max_output_lines: 200

  # Patrones regex adicionales a bloquear (además de los built-in).
  # Los built-in ya bloquean: rm -rf /, sudo, chmod 777, curl|bash, etc.
  blocked_patterns: []
  # blocked_patterns:
  #   - "docker rm"           # Bloquear eliminación de contenedores
  #   - "git push --force"    # Bloquear force push

  # Comandos adicionales considerados seguros (sin confirmación en confirm-sensitive).
  # Se suman a los built-in: ls, cat, git status, git log, python --version, etc.
  safe_commands: []
  # safe_commands:
  #   - "my-lint-script.sh"
  #   - "pnpm test:watch"

  # Si true, solo se permiten comandos clasificados como safe o dev.
  # Los comandos desconocidos son rechazados en execute() (no solo en confirmación).
  # Útil para CI/pipelines donde quieres whitelist estricto.
  allowed_only: false


# ==============================================================================
# Costs - Seguimiento de costes de llamadas al LLM (F14)
# ==============================================================================
# Registra el coste de cada llamada al LLM en USD, con desglose por fuente
# (agent/eval/summary) y soporte para presupuesto máximo por ejecución.
#
# El coste total se incluye en el JSON output (--json) y se muestra en consola
# con --show-costs o -v.
#
# Override desde CLI:
#   --budget 0.5       → Detener si se superan $0.50
#   --show-costs       → Mostrar resumen de costes al terminar
costs:
  # Si false, no se registran costes (deshabilita toda la sección).
  enabled: true

  # Path a un archivo JSON con precios custom (mismo formato que default_prices.json).
  # Si no se especifica, se usan los precios embebidos del paquete.
  # prices_file: my_prices.json

  # Límite máximo de gasto en USD por ejecución.
  # Si el coste acumulado supera este valor, el agente se detiene con status "partial".
  # None = sin límite (default).
  # budget_usd: 1.0

  # Umbral de aviso en USD. Cuando el gasto alcanza este valor se emite
  # un log warning (sin detener la ejecución). None = sin aviso.
  # warn_at_usd: 0.5


# ==============================================================================
# LLM Cache - Cache local de respuestas LLM para desarrollo (F14)
# ==============================================================================
# Cache determinista en disco: guarda respuestas completas del LLM para evitar
# llamadas repetidas cuando los mensajes son idénticos.
#
# ATENCIÓN: Solo para desarrollo. No usar en producción.
#
# Override desde CLI:
#   --cache           → Activar cache local
#   --no-cache        → Desactivar aunque esté habilitado en config
#   --cache-clear     → Limpiar cache antes de ejecutar
llm_cache:
  # Si false, el cache no se usa (default — seguro para producción).
  # Activar con: architect run "..." --cache
  enabled: false

  # Directorio donde guardar las entradas de cache.
  dir: ~/.architect/cache

  # Horas de validez de cada entrada. Entradas más antiguas se ignoran.
  # Rango: 1-8760 (1 hora a 1 año).
  ttl_hours: 24


# ==============================================================================
# Hooks - Post-edit hooks (verificación automática tras editar)
# ==============================================================================
# Los hooks se ejecutan automáticamente después de que el agente edite, cree
# o parchee un archivo (edit_file, write_file, apply_patch).
# Permiten verificar que los cambios son correctos: lint, typecheck, tests.
#
# El output del hook se devuelve al agente como parte del resultado de la tool,
# para que pueda corregir errores automáticamente.
#
# Cada hook puede filtrar por patrón de archivo (file_patterns glob).
# Si file_patterns está vacío, el hook se ejecuta para cualquier archivo.
hooks:
  post_edit: []

  # ── Ejemplo: ruff en archivos Python ────────────────────────────────────────
  # post_edit:
  #   - name: ruff
  #     command: ruff check --fix {file}
  #     file_patterns:
  #       - "*.py"
  #     timeout: 15
  #     enabled: true

  # ── Ejemplo: typecheck con mypy ─────────────────────────────────────────────
  #   - name: mypy
  #     command: mypy {file} --ignore-missing-imports
  #     file_patterns:
  #       - "*.py"
  #     timeout: 30
  #     enabled: true

  # ── Ejemplo: eslint en archivos JS/TS ───────────────────────────────────────
  #   - name: eslint
  #     command: npx eslint --fix {file}
  #     file_patterns:
  #       - "*.js"
  #       - "*.ts"
  #       - "*.tsx"
  #     timeout: 20
  #     enabled: true
